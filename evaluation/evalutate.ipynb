{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text_in, tok_in, mod_in):\n",
    "    tok_text = tok_in(text_in, return_tensors='pt').to('cuda:0')\n",
    "    gen_text = mod_in.generate(**tok_text, max_new_tokens=512)\n",
    "    dec_text = tok_in.decode(gen_text[0], skip_special_tokens=True)\n",
    "    return dec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v0.3 and are newly initialized: ['model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.3\")\n",
    "\n",
    "# tuned_model = AutoModelForCausalLM.from_pretrained(\"../finetuning/tuned_model/\", torch_dtype=torch.float32)\n",
    "baseline_model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.3\", torch_dtype=torch.float32)\n",
    "# rlhf_model = AutoModelForCausalLM.from_pretrained(\"../Reward Model/model/\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32003, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32003, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>language</th>\n",
       "      <th>filename_ext</th>\n",
       "      <th>status</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>memory</th>\n",
       "      <th>code_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>solution</th>\n",
       "      <th>problem_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619278</td>\n",
       "      <td>5172</td>\n",
       "      <td>s373894550</td>\n",
       "      <td>p03202</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>2741</td>\n",
       "      <td>None</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>Score : 700 points \\n Problem Statement There ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771169</td>\n",
       "      <td>5835</td>\n",
       "      <td>s440823744</td>\n",
       "      <td>p03008</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>176.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1378</td>\n",
       "      <td>None</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n\\nusing namespace st...</td>\n",
       "      <td>Score : 600 points \\n Problem Statement The sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654494</td>\n",
       "      <td>7516</td>\n",
       "      <td>s716084373</td>\n",
       "      <td>p03943</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>88</td>\n",
       "      <td>None</td>\n",
       "      <td>a, b, c = map(int, input().split())\\n\\nif a ==...</td>\n",
       "      <td>Score : 100 points \\n Problem Statement Two st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758900</td>\n",
       "      <td>5870</td>\n",
       "      <td>s029981993</td>\n",
       "      <td>p03047</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>n,k = map(int,input().split())\\nprint(n-k+1)</td>\n",
       "      <td>Score : 100 points \\n Problem Statement Snuke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2792852</td>\n",
       "      <td>1786</td>\n",
       "      <td>s487610428</td>\n",
       "      <td>p03852</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>168.0</td>\n",
       "      <td>38384.0</td>\n",
       "      <td>114</td>\n",
       "      <td>None</td>\n",
       "      <td>c = input()\\n\\nif c == \"a\" or c == \"i\" or c ==...</td>\n",
       "      <td>Score : 100 points \\n Problem Statement Given ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index submission_id problem_id language filename_ext  \\\n",
       "0  1619278   5172    s373894550     p03202      C++          cpp   \n",
       "1   771169   5835    s440823744     p03008      C++          cpp   \n",
       "2  1654494   7516    s716084373     p03943   Python           py   \n",
       "3   758900   5870    s029981993     p03047   Python           py   \n",
       "4  2792852   1786    s487610428     p03852   Python           py   \n",
       "\n",
       "         status  cpu_time   memory  code_size accuracy  \\\n",
       "0  Wrong Answer    2103.0   1916.0       2741     None   \n",
       "1  Wrong Answer     176.0    256.0       1378     None   \n",
       "2  Wrong Answer      17.0   2940.0         88     None   \n",
       "3      Accepted      17.0   2940.0         43     None   \n",
       "4      Accepted     168.0  38384.0        114     None   \n",
       "\n",
       "                                            solution  \\\n",
       "0  #include <bits/stdc++.h>\\nusing namespace std;...   \n",
       "1  #include <bits/stdc++.h>\\n\\nusing namespace st...   \n",
       "2  a, b, c = map(int, input().split())\\n\\nif a ==...   \n",
       "3       n,k = map(int,input().split())\\nprint(n-k+1)   \n",
       "4  c = input()\\n\\nif c == \"a\" or c == \"i\" or c ==...   \n",
       "\n",
       "                                   problem_statement  \n",
       "0  Score : 700 points \\n Problem Statement There ...  \n",
       "1  Score : 600 points \\n Problem Statement The sq...  \n",
       "2  Score : 100 points \\n Problem Statement Two st...  \n",
       "3  Score : 100 points \\n Problem Statement Snuke ...  \n",
       "4  Score : 100 points \\n Problem Statement Given ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather('../mini_codenet/data/split/evaluate_train.ftr')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p02402</td>\n",
       "      <td>5\\n10 1 5 4 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p03316</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p02995</td>\n",
       "      <td>4 9 2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p03129</td>\n",
       "      <td>3 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p02612</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a               b\n",
       "0  p02402  5\\n10 1 5 4 17\n",
       "1  p03316              12\n",
       "2  p02995         4 9 2 3\n",
       "3  p03129             3 2\n",
       "4  p02612            1900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_feather('./file.feather')\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [13:48<00:00, 16.58s/it]\n"
     ]
    }
   ],
   "source": [
    "num_compiled = 0\n",
    "num_checked = 0\n",
    "dist = len(os.listdir('./baseline_files/'))\n",
    "print(dist)\n",
    "for pid in tqdm(set(eval_df['a'].values)):\n",
    "    if num_checked >= dist-1:\n",
    "        instance = df.loc[(df['status'] == 'Accepted') & (df['language'] == 'Python') & (df['problem_id'] == pid)]\n",
    "        \n",
    "        prompt = instance.iloc[0]['problem_statement']\n",
    "        prompt = prompt.replace('\\n', '')\n",
    "        lang = instance.iloc[0]['language']\n",
    "        # ------ baseline -------\n",
    "        formatted_prompt = (f\"<|im_start|>user\\nGenerate the correct {lang} code to answer the following prompt that can also takens input and prints out an answer:{prompt}<|im_end|>\\n<|im_start|>assistant\\n\")\n",
    "        generated = generate(formatted_prompt, tokenizer, baseline_model)\n",
    "        try:\n",
    "            baseline_generated = re.search(f'```{lang.lower()}(\\n|.)*```', generated).group()\n",
    "        except:\n",
    "            baseline_generated = re.search(f'```{lang.lower()}(\\n|.)*```', generated+'```').group()\n",
    "        #print(baseline_generated)\n",
    "        try:\n",
    "            open(f'./baseline_files/{num_checked}.txt', 'w', encoding=\"utf-8\").write(baseline_generated)\n",
    "        except:\n",
    "            open(f'./baseline_files/{num_checked}.txt', 'w', encoding=\"utf-8\").write(generated)\n",
    "        try:\n",
    "            x = compile(baseline_generated[3+len(lang):-3], 'test', 'exec')\n",
    "            num_compiled += 1\n",
    "            num_checked += 1\n",
    "        except:\n",
    "            num_checked += 1\n",
    "            continue\n",
    "    else:\n",
    "        num_checked += 1\n",
    "    #out = exec(x)\n",
    "    #print(out)\n",
    "# ------ finetuned -------\n",
    "# formatted_prompt = (f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistantPython\\n\") # update this with newest model\n",
    "# generated = generate(formatted_prompt, tokenizer, tuned_model)\n",
    "# fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_generated = re.search(f'```{lang.lower()}(\\n|.)*```', generated).group()\n",
    "print(baseline_generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
