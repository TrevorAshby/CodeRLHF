{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from trl import RewardConfig, RewardTrainer\n",
    "from peft import LoraConfig, TaskType # Parameter Efficient Fine Tuning\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrevorashby\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to Weights and Biases for training logging\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN = pd.read_feather(\"../mini_codenet/data/split/reward_train.ftr\")\n",
    "DATASET_EVAL = pd.read_feather(\"../mini_codenet/data/split/reward_val.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>language</th>\n",
       "      <th>filename_ext</th>\n",
       "      <th>status</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>memory</th>\n",
       "      <th>code_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>solution</th>\n",
       "      <th>problem_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732215</td>\n",
       "      <td>1955</td>\n",
       "      <td>s679316564</td>\n",
       "      <td>p02629</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9096.0</td>\n",
       "      <td>166</td>\n",
       "      <td>None</td>\n",
       "      <td>n = int(input())\\nc = \" \"\\nwhile n:\\n    if n ...</td>\n",
       "      <td>Score : 300 points \\n Problem Statement 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2873817</td>\n",
       "      <td>1241</td>\n",
       "      <td>s424811397</td>\n",
       "      <td>p03700</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>711</td>\n",
       "      <td>None</td>\n",
       "      <td>#include&lt;iostream&gt;\\n#include&lt;queue&gt;\\nusing nam...</td>\n",
       "      <td>Score : 400 points \\n Problem Statement You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2117312</td>\n",
       "      <td>2364</td>\n",
       "      <td>s962040422</td>\n",
       "      <td>p02904</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>2852</td>\n",
       "      <td>None</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n//#include &lt;tr1/unor...</td>\n",
       "      <td>Score : 700 points \\n Problem Statement Snuke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494734</td>\n",
       "      <td>7691</td>\n",
       "      <td>s601052755</td>\n",
       "      <td>p02945</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>147</td>\n",
       "      <td>None</td>\n",
       "      <td>#include \"bits/stdc++.h\"\\n\\nusing namespace st...</td>\n",
       "      <td>Score : 100 points \\n Problem Statement We hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2040572</td>\n",
       "      <td>8188</td>\n",
       "      <td>s811638706</td>\n",
       "      <td>p03574</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3188.0</td>\n",
       "      <td>486</td>\n",
       "      <td>None</td>\n",
       "      <td>h, w = map(int, input().split())\\ns = [[\"a\"]*(...</td>\n",
       "      <td>Score : 200 points \\n Problem Statement You ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index submission_id problem_id language filename_ext  \\\n",
       "0   732215   1955    s679316564     p02629   Python           py   \n",
       "1  2873817   1241    s424811397     p03700      C++          cpp   \n",
       "2  2117312   2364    s962040422     p02904      C++          cpp   \n",
       "3   494734   7691    s601052755     p02945      C++          cpp   \n",
       "4  2040572   8188    s811638706     p03574   Python           py   \n",
       "\n",
       "         status  cpu_time   memory  code_size accuracy  \\\n",
       "0      Accepted      27.0   9096.0        166     None   \n",
       "1      Accepted      91.0   1024.0        711     None   \n",
       "2  Wrong Answer      17.0  14336.0       2852     None   \n",
       "3      Accepted       1.0    256.0        147     None   \n",
       "4      Accepted      27.0   3188.0        486     None   \n",
       "\n",
       "                                            solution  \\\n",
       "0  n = int(input())\\nc = \" \"\\nwhile n:\\n    if n ...   \n",
       "1  #include<iostream>\\n#include<queue>\\nusing nam...   \n",
       "2  #include <bits/stdc++.h>\\n//#include <tr1/unor...   \n",
       "3  #include \"bits/stdc++.h\"\\n\\nusing namespace st...   \n",
       "4  h, w = map(int, input().split())\\ns = [[\"a\"]*(...   \n",
       "\n",
       "                                   problem_statement  \n",
       "0  Score : 300 points \\n Problem Statement 100000...  \n",
       "1  Score : 400 points \\n Problem Statement You ar...  \n",
       "2  Score : 700 points \\n Problem Statement Snuke ...  \n",
       "3  Score : 100 points \\n Problem Statement We hav...  \n",
       "4  Score : 200 points \\n Problem Statement You ar...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status\n",
       "Accepted                  358603\n",
       "Compile Error              24979\n",
       "Memory Limit Exceeded        542\n",
       "Output Limit Exceeded         48\n",
       "Query Limit Exceeded           2\n",
       "Runtime Error              41398\n",
       "Time Limit Exceeded        36160\n",
       "WA: Presentation Error      2763\n",
       "Wrong Answer              201829\n",
       "Name: solution, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(DATASET_TRAIN))\n",
    "DATASET_TRAIN.groupby(\"status\")[\"solution\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>language</th>\n",
       "      <th>filename_ext</th>\n",
       "      <th>status</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>memory</th>\n",
       "      <th>code_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>solution</th>\n",
       "      <th>problem_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2360322</td>\n",
       "      <td>5322</td>\n",
       "      <td>s850061551</td>\n",
       "      <td>p03288</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>213</td>\n",
       "      <td>None</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>Score : 100 points \\n Problem Statement A prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2047495</td>\n",
       "      <td>7500</td>\n",
       "      <td>s837081478</td>\n",
       "      <td>p03548</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>183</td>\n",
       "      <td>None</td>\n",
       "      <td>#include&lt;stdio.h&gt;\\n#include&lt;string.h&gt;\\n#includ...</td>\n",
       "      <td>Score : 200 points \\n Problem Statement We hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119655</td>\n",
       "      <td>7092</td>\n",
       "      <td>s828220597</td>\n",
       "      <td>p03308</td>\n",
       "      <td>C++</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Compile Error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406</td>\n",
       "      <td>None</td>\n",
       "      <td>#include &lt;iostream&gt;\\n#include &lt;string&gt;\\n#inclu...</td>\n",
       "      <td>Score : 200 points \\n Problem Statement You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1327179</td>\n",
       "      <td>1296</td>\n",
       "      <td>s282902347</td>\n",
       "      <td>p02924</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9008.0</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>n = int(input())\\nans = int(1/2 * n * (n-1))\\n...</td>\n",
       "      <td>Score : 400 points \\n Problem Statement For an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2153223</td>\n",
       "      <td>1499</td>\n",
       "      <td>s083246489</td>\n",
       "      <td>p03944</td>\n",
       "      <td>Python</td>\n",
       "      <td>py</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>323</td>\n",
       "      <td>None</td>\n",
       "      <td>w, h, n = map(int, input().split())\\nx_reg = 0...</td>\n",
       "      <td>Score : 200 points \\n Problem Statement There ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index submission_id problem_id language filename_ext  \\\n",
       "0  2360322   5322    s850061551     p03288      C++          cpp   \n",
       "1  2047495   7500    s837081478     p03548        C            c   \n",
       "2   119655   7092    s828220597     p03308      C++          cpp   \n",
       "3  1327179   1296    s282902347     p02924   Python           py   \n",
       "4  2153223   1499    s083246489     p03944   Python           py   \n",
       "\n",
       "          status  cpu_time  memory  code_size accuracy  \\\n",
       "0       Accepted       1.0   256.0        213     None   \n",
       "1       Accepted       1.0   128.0        183     None   \n",
       "2  Compile Error       NaN     NaN        406     None   \n",
       "3   Wrong Answer      28.0  9008.0         54     None   \n",
       "4   Wrong Answer      17.0  3064.0        323     None   \n",
       "\n",
       "                                            solution  \\\n",
       "0  #include <bits/stdc++.h>\\nusing namespace std;...   \n",
       "1  #include<stdio.h>\\n#include<string.h>\\n#includ...   \n",
       "2  #include <iostream>\\n#include <string>\\n#inclu...   \n",
       "3  n = int(input())\\nans = int(1/2 * n * (n-1))\\n...   \n",
       "4  w, h, n = map(int, input().split())\\nx_reg = 0...   \n",
       "\n",
       "                                   problem_statement  \n",
       "0  Score : 100 points \\n Problem Statement A prog...  \n",
       "1  Score : 200 points \\n Problem Statement We hav...  \n",
       "2  Score : 200 points \\n Problem Statement You ar...  \n",
       "3  Score : 400 points \\n Problem Statement For an...  \n",
       "4  Score : 200 points \\n Problem Statement There ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status\n",
       "Accepted                  102749\n",
       "Compile Error               7135\n",
       "Memory Limit Exceeded        156\n",
       "Output Limit Exceeded          8\n",
       "Query Limit Exceeded           1\n",
       "Runtime Error              11691\n",
       "Time Limit Exceeded        10223\n",
       "WA: Presentation Error       747\n",
       "Wrong Answer               57669\n",
       "Name: solution, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(DATASET_EVAL))\n",
    "DATASET_EVAL.groupby(\"status\")[\"solution\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accepted Problems in TRAIN: 358603\n",
      "Total Rejected Problems in TRAIN: 307721\n",
      "Unique IDs in Accepted TRAIN: 2450\n",
      "Unique IDs in Rejected TRAIN: 2359\n",
      "------------\n",
      "Total Accepted Problems in EVAL: 102749\n",
      "Total Rejected Problems in EVAL: 87630\n",
      "Unique IDs in Accepted EVAL: 2188\n",
      "Unique IDs in Rejected EVAL: 2124\n"
     ]
    }
   ],
   "source": [
    "# Sample 1000 accepted solutions at random.\n",
    "accepted_train = DATASET_TRAIN[DATASET_TRAIN[\"status\"] == \"Accepted\"][[\"submission_id\", \"problem_id\", \"language\", \"solution\"]]\n",
    "rejected_train = DATASET_TRAIN[DATASET_TRAIN[\"status\"] != \"Accepted\"][[\"submission_id\", \"problem_id\", \"language\", \"solution\"]]\n",
    "accepted_eval = DATASET_EVAL[DATASET_EVAL[\"status\"] == \"Accepted\"][[\"submission_id\", \"problem_id\", \"language\", \"solution\"]]\n",
    "rejected_eval = DATASET_EVAL[DATASET_EVAL[\"status\"] != \"Accepted\"][[\"submission_id\", \"problem_id\", \"language\", \"solution\"]]\n",
    "\n",
    "print(\"Total Accepted Problems in TRAIN:\", len(accepted_train[\"submission_id\"]))\n",
    "print(\"Total Rejected Problems in TRAIN:\", len(rejected_train[\"submission_id\"]))\n",
    "print(\"Unique IDs in Accepted TRAIN:\", len(accepted_train[\"problem_id\"].unique()))\n",
    "print(\"Unique IDs in Rejected TRAIN:\", len(rejected_train[\"problem_id\"].unique()))\n",
    "print(\"------------\")\n",
    "print(\"Total Accepted Problems in EVAL:\", len(accepted_eval[\"submission_id\"]))\n",
    "print(\"Total Rejected Problems in EVAL:\", len(rejected_eval[\"submission_id\"]))\n",
    "print(\"Unique IDs in Accepted EVAL:\", len(accepted_eval[\"problem_id\"].unique()))\n",
    "print(\"Unique IDs in Rejected EVAL:\", len(rejected_eval[\"problem_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each accepted solution, chose a contrasting rejected \n",
    "def get_contrastive_pairs(data_accepted, data_rejected, n=3):\n",
    "    data = { \"accepted\": [], \"rejected\": [] }\n",
    "\n",
    "    # SPEED UP!! Group rejected answers by problem_id and language and cache the results so\n",
    "    # we do not have to filter the whole dataset inside the main for-loop on every iteration.\n",
    "    # Plus, we get O(1) look up time ðŸ˜Ž\n",
    "    grouped_rejected = data_rejected.groupby([\"problem_id\", \"language\"])[\"solution\"].apply(list).to_dict()\n",
    "\n",
    "    for _, accepted_pid, accepted_lang, accepted_sol in tqdm(data_accepted.values):\n",
    "        key = (accepted_pid, accepted_lang)\n",
    "\n",
    "        if key in grouped_rejected:\n",
    "            # Get up to `n`` rejected examples in the current language for the current problem.\n",
    "            rejected_filtered = grouped_rejected[key]\n",
    "\n",
    "            size = min(len(rejected_filtered), n)\n",
    "            for idx in np.random.randint(0, len(rejected_filtered), size):\n",
    "                data[\"accepted\"].append(accepted_sol)\n",
    "                data[\"rejected\"].append(rejected_filtered[idx])\n",
    "        else:\n",
    "            # The problem only contains a correct solutions in the current language. Skip it.\n",
    "            pass\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "# Tokenize chosen/rejected pairs of inputs\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    new_examples = {\n",
    "        \"input_ids_chosen\": [],\n",
    "        \"attention_mask_chosen\": [],\n",
    "        \"input_ids_rejected\": [],\n",
    "        \"attention_mask_rejected\": [],\n",
    "    }\n",
    "\n",
    "    for chosen, rejected in zip(examples[\"accepted\"], examples[\"rejected\"]):\n",
    "        tokenized_chosen = tokenizer(chosen)\n",
    "        tokenized_rejected = tokenizer(rejected)\n",
    "\n",
    "        new_examples[\"input_ids_chosen\"].append(tokenized_chosen[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_chosen\"].append(tokenized_chosen[\"attention_mask\"])\n",
    "        new_examples[\"input_ids_rejected\"].append(tokenized_rejected[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_rejected\"].append(tokenized_rejected[\"attention_mask\"])\n",
    "\n",
    "    return new_examples\n",
    "\n",
    "# Preprocess the dataset and filter out examples that are longer than args.max_length\n",
    "def process_data(accepted, rejected, tokenizer, args):\n",
    "    dataset = get_contrastive_pairs(accepted, rejected)\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda example: preprocess_function(example, tokenizer),\n",
    "        batched=True,\n",
    "        #num_proc=4,\n",
    "    )\n",
    "\n",
    "    dataset = dataset.filter(\n",
    "        lambda x: len(x[\"input_ids_chosen\"]) <= args.reward_config.max_length\n",
    "        and len(x[\"input_ids_rejected\"]) <= args.reward_config.max_length\n",
    "    )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    model_name: str = \"../finetuning/hf_model/\" # TODO: Change path to correct SFT model\n",
    "    \"\"\"the model name\"\"\"\n",
    "    eval_split: bool = False\n",
    "    \"\"\"the dataset split to evaluate on; default to 'none' (no evaluation)\"\"\"\n",
    "    reward_config: RewardConfig = field(\n",
    "        default_factory=lambda: RewardConfig(\n",
    "            output_dir=\"output\",\n",
    "            per_device_train_batch_size=64,\n",
    "            num_train_epochs=10,\n",
    "            gradient_accumulation_steps=16,\n",
    "            gradient_checkpointing=True,\n",
    "            gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "            learning_rate=1.41e-5,\n",
    "            report_to=\"wandb\", # log training progress to Weights and Biases\n",
    "            remove_unused_columns=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            logging_steps=500,\n",
    "            evaluation_strategy=\"no\",\n",
    "            max_length=256, # TODO: NEED TO CHANGE THIS!\n",
    "        )\n",
    "    )\n",
    "\n",
    "args = ScriptArguments()\n",
    "args.reward_config.evaluation_strategy = \"steps\" if args.eval_split else \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset and pre-process it\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 358603/358603 [00:10<00:00, 33452.72it/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1068246/1068246 [43:46<00:00, 406.79 examples/s] \n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1068246/1068246 [22:57<00:00, 775.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102749/102749 [00:03<00:00, 31615.77it/s]\n",
      "Map:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 282000/301682 [12:44<00:53, 369.01 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ma:\\VirginiaTech\\School\\Fall23\\CS5806-ML\\CodeRLHF\\Reward Model\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m process_data(accepted_train, rejected_train, tokenizer, args)\n\u001b[0;32m      <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEvaluation Data:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m eval_dataset \u001b[39m=\u001b[39m process_data(accepted_eval, rejected_eval, tokenizer, args)\n",
      "\u001b[1;32ma:\\VirginiaTech\\School\\Fall23\\CS5806-ML\\CodeRLHF\\Reward Model\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_data\u001b[39m(accepted, rejected, tokenizer, args):\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     dataset \u001b[39m=\u001b[39m get_contrastive_pairs(accepted, rejected)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m example: preprocess_function(example, tokenizer),\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         \u001b[39m#num_proc=4,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mfilter(\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids_chosen\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mreward_config\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids_rejected\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mreward_config\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3466\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3462\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   3463\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   3464\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3465\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3466\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[0;32m   3467\u001b[0m         batch,\n\u001b[0;32m   3468\u001b[0m         indices,\n\u001b[0;32m   3469\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   3470\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   3471\u001b[0m     )\n\u001b[0;32m   3472\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3473\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3474\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3475\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3343\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39mfn_args, \u001b[39m*\u001b[39madditional_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3347\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3348\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3349\u001b[0m     }\n",
      "\u001b[1;32ma:\\VirginiaTech\\School\\Fall23\\CS5806-ML\\CodeRLHF\\Reward Model\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_data\u001b[39m(accepted, rejected, tokenizer, args):\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     dataset \u001b[39m=\u001b[39m get_contrastive_pairs(accepted, rejected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m example: preprocess_function(example, tokenizer),\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         \u001b[39m#num_proc=4,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mfilter(\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids_chosen\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mreward_config\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids_rejected\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mreward_config\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\n",
      "\u001b[1;32ma:\\VirginiaTech\\School\\Fall23\\CS5806-ML\\CodeRLHF\\Reward Model\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m new_examples \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_ids_chosen\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mattention_mask_chosen\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_ids_rejected\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mattention_mask_rejected\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m chosen, rejected \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(examples[\u001b[39m\"\u001b[39m\u001b[39maccepted\u001b[39m\u001b[39m\"\u001b[39m], examples[\u001b[39m\"\u001b[39m\u001b[39mrejected\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     tokenized_chosen \u001b[39m=\u001b[39m tokenizer(chosen)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     tokenized_rejected \u001b[39m=\u001b[39m tokenizer(rejected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/VirginiaTech/School/Fall23/CS5806-ML/CodeRLHF/Reward%20Model/main.ipynb#X41sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     new_examples[\u001b[39m\"\u001b[39m\u001b[39minput_ids_chosen\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(tokenized_chosen[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2577\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2575\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2576\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2577\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_one(text\u001b[39m=\u001b[39mtext, text_pair\u001b[39m=\u001b[39mtext_pair, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs)\n\u001b[0;32m   2578\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2683\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2663\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2664\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2665\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2681\u001b[0m     )\n\u001b[0;32m   2682\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2683\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2684\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2685\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2686\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2687\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2688\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   2689\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2690\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2691\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2692\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2693\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2694\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2695\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2696\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2697\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2698\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2699\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2700\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2702\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2756\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2747\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2748\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2749\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2753\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2754\u001b[0m )\n\u001b[1;32m-> 2756\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_plus(\n\u001b[0;32m   2757\u001b[0m     text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2758\u001b[0m     text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2759\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2760\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2761\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2762\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2763\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2764\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2765\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2766\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2767\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2768\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2769\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2770\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2771\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2772\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2773\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2774\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2775\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:497\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[0;32m    476\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    495\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[0;32m    496\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[1;32m--> 497\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    498\u001b[0m         batched_input,\n\u001b[0;32m    499\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m    500\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m    501\u001b[0m         padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    502\u001b[0m         truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    503\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m    504\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m    505\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    506\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m    507\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    508\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    509\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    510\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    511\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    512\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m    513\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    514\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    517\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:425\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    418\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    419\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    423\u001b[0m )\n\u001b[1;32m--> 425\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    426\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    427\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    428\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    431\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    437\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    438\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    439\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    449\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\")\n",
    "train_dataset = process_data(accepted_train, rejected_train, tokenizer, args)\n",
    "\n",
    "print(\"\\nEvaluation Data:\")\n",
    "eval_dataset = process_data(accepted_eval, rejected_eval, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(args.model_name, num_labels=1)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the Trainer\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args.reward_config,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
